name: 'Deploy Single VM Stackstorm to AWS EC2'
description: 'Deploy a Single VM Stackstorm to an AWS Virtual Machine (EC2)'
branding:
  icon: upload-cloud
  color: red
inputs:
  checkout:
    description: 'Specifies if this action should checkout the code'
    required: false
    default: "true"

  # AWS Configuration
  aws_access_key_id:
    description: 'AWS access key ID'
    required: true
  aws_secret_access_key:
    description: 'AWS secret access key'
    required: true
  aws_session_token:
    description: "AWS session token, if you're using temporary credentials"
    required: false
  aws_default_region:
    description: 'AWS default region'
    required: true
    default: us-east-1
  aws_ec2_instance_type:
    description: 'The AWS EC2 instance type'
    default: t2.medium
  aws_ec2_instance_profile:
    description: 'The AWS IAM instance profile to use for the EC2 instance. Use if you want to pass an AWS role with specific permissions granted to the instance'
  aws_resource_identifier:
    description: "Auto-generated by default so it's unique for org/repo/branch. Set to override with custom naming the unique AWS resource identifier for the deployment. Defaults to `${org}-${repo}-${branch}`."
  aws_create_vpc:
    description: 'Bool, whether an AWS VPC should be created in the action. Otherwise, the existing default VPC will be used.'
    default: "false"
  aws_extra_tags:
    description: 'A list of additional tags that will be included on created resources. Example: `{"key1": "value1", "key2": "value2"}`'
    required: false
    default: '{}'
  infrastructure_only:
    description: 'Set to true to provision infrastructure (with Terraform) but skip the app deployment (with ansible)'
    default: "false"


  # Terraform configuration
  tf_state_bucket:
    description: 'AWS S3 bucket to use for Terraform state. Defaults to `${org}-${repo}-${branch}-tf-state`'
    required: false

  # StackStorm configuration
  st2_auth_username:
    description: 'Username used by StackStorm standalone authentication. Set as a secret in GH Actions.'
    required: true
  st2_auth_password:
    description: 'Password used by StackStorm standalone authentication. Set as a secret in GH Actions.'
    required: true
  st2_packs:
    description: 'Comma separated list of packs to install. If you modify this option, be sure to also include `st2` in the list.'
    default: "st2"
  st2_ansible_extra_vars_file:
     description: "Relative path from project root to Ansible vars file. If you'd like to adjust more advanced configuration; st2 version, st2.conf, RBAC, chatops, auth, etc. See https://github.com/stackStorm/ansible-st2#variables for the full list of settings. The Ansible vars will take higher precedence over the GHA inputs."

  # Cleanup
  tf_stack_destroy:
    description: 'Set to "true" to Destroy the created AWS infrastructure for this instance'
    default: "false"
  tf_state_bucket_destroy:
    description: 'Force purge and deletion of tf_state_bucket defined. Any file contained there will be destroyed. tf_stack_destroy must also be true.'
    default: "false"

  # Domains
  aws_domain_name:
    description: "Define the root domain name for the application. e.g. bitovi.com. If empty, ELB URL will be provided."
    required: false
  aws_sub_domain:
    description: 'Define the sub-domain part of the URL. Defaults to `${org}-${repo}-{branch}`'
  aws_root_domain:
    description: 'Deploy application to root domain. Will create root and www DNS records. Domain must exist in Route53.'
    required: false
  aws_cert_arn:
    description: 'Existing certificate ARN to be used in the ELB. Use if you manage a certificate outside of this action. See https://docs.aws.amazon.com/acm/latest/userguide/gs-acm-list.html for how to find the certificate ARN.'
    required: false
  aws_create_root_cert:
    description: 'Generates and manage the root certificate for the application to be used in the ELB.'
    required: false
  aws_create_sub_cert: 
    description: 'Generates and manage the sub-domain certificate for the application to be used in the ELB.'
    required: false
  aws_no_cert:
    description: 'Set this to true if you want not to use a certificate in the ELB.'
    default: false
    required: false

outputs:
  vm_url:
    description: 'The URL of the generated app'
    value: ${{ steps.deploy.outputs.vm_url }}

#runs:
#  using: 'composite'
#  steps:
#    - name: Checkout if required
#      if: ${{ inputs.checkout == 'true' }}
#      uses: actions/checkout@v3
#
#    - name: Deploy with BitOps
#      id: deploy
#      shell: bash
#      env:
#        GITHUB_ACTION_PATH: ${{ github.action_path }}
#        BITOPS_ENVIRONMENT: deployment
#        AWS_ACCESS_KEY_ID: ${{ inputs.aws_access_key_id }}
#        AWS_SECRET_ACCESS_KEY: ${{ inputs.aws_secret_access_key }}
#        AWS_SESSION_TOKEN: ${{ inputs.aws_session_token }}
#        AWS_DEFAULT_REGION: ${{ inputs.aws_default_region }}
#        TF_STATE_BUCKET: ${{ inputs.tf_state_bucket }}
#        TF_STATE_BUCKET_DESTROY: ${{ inputs.tf_state_bucket_destroy }}
#
#        EC2_INSTANCE_PROFILE: ${{ inputs.aws_ec2_instance_profile }}
#        EC2_INSTANCE_TYPE: ${{ inputs.aws_ec2_instance_type }}
#        STACK_DESTROY: ${{ inputs.tf_stack_destroy }}
#        AWS_RESOURCE_IDENTIFIER: ${{ inputs.aws_resource_identifier }}
#        CREATE_VPC: ${{ inputs.aws_create_vpc }}
#        AWS_EXTRA_TAGS: ${{ inputs.aws_extra_tags }}
#
#        # Domain / cert management
#        DOMAIN_NAME: ${{ inputs.aws_domain_name }}
#        SUB_DOMAIN: ${{ inputs.aws_sub_domain }}
#        ROOT_DOMAIN: ${{ inputs.aws_root_domain }}
#        CERT_ARN: ${{ inputs.aws_cert_arn }}
#        CREATE_ROOT_CERT: ${{ inputs.aws_create_root_cert }}
#        CREATE_SUB_CERT: ${{ inputs.aws_create_sub_cert }}
#        NO_CERT: ${{ inputs.aws_no_cert }}
#
#        # Skip ansible deployment if deploying only infrastructure
#        ANSIBLE_SKIP_DEPLOY: ${{ inputs.infrastructure_only }}
#
#        # ST2 config
#        ST2_AUTH_USERNAME: ${{ inputs.st2_auth_username }}
#        ST2_AUTH_PASSWORD: ${{ inputs.st2_auth_password }}
#        ST2_PACKS: ${{ inputs.st2_packs }}
#        ST2_ANSIBLE_EXTRA_VARS_FILE: ${{ inputs.st2_ansible_extra_vars_file }}
#      run: |
#        echo "running operations/_scripts/deploy/deploy.sh"
#        $GITHUB_ACTION_PATH/operations/_scripts/deploy/deploy.sh
#
#        echo "Setting up vars for GitHub"
#        $GITHUB_ACTION_PATH/operations/_scripts/deploy/export_vars.sh
#
#    # output results to GitHub
#    - if: ${{ steps.deploy.outputs.vm_url != '' }}
#      name: Print result created
#      shell: bash
#      run: |
#        echo "## VM Created! :rocket:" >> $GITHUB_STEP_SUMMARY
#        echo " ${{ steps.deploy.outputs.vm_url }}" >> $GITHUB_STEP_SUMMARY
#    - if: ${{ steps.deploy.outputs.vm_url == '' }}
#      name: Print result destroyed
#      shell: bash
#      run: |
#        echo "## VM Destroyed! :boom:" >> $GITHUB_STEP_SUMMARY
#        echo "Buckets and whole infrastructure should be gone now!" >> $GITHUB_STEP_SUMMARY


runs:
  using: 'composite'
  steps:
    - name: Invert boolean Variable
      shell: bash
      id: set-cert
      if: ${{ inputs.aws_no_cert == 'false' }}
      run: echo "enable_cert=true" >> $GITHUB_OUTPUT
      
    - name: Deploy with BitOps
      id: deploy
      uses: bitovi/github-actions-commons@13-add-support-to-add-terraform-ansible-code
      with:
        # Current repo vars
        gh_calling_repo: ${{ github.action_path }}
        gh_input_ansible: operations/deployment/ansible

        # Action main inputs
        checkout: ${{ inputs.checkout }}
        tf_stack_destroy: ${{ inputs.tf_stack_destroy }}
        tf_state_bucket: ${{ inputs.tf_state_bucket }}
        tf_state_bucket_destroy: ${{ inputs.tf_state_bucket_destroy }}
        tf_state_bucket_provider: 'aws'
        #tf_targets: ''
        ansible_skip : ${{ inputs.infrastructure_only }}


        # AWS - ALL CHECK
        aws_access_key_id: ${{ inputs.aws_access_key_id }}
        aws_secret_access_key: ${{ inputs.aws_secret_access_key }}
        aws_session_token: ${{ inputs.aws_session_token }}
        aws_default_region: ${{ inputs.aws_default_region }}
        aws_resource_identifier: ${{ inputs.aws_resource_identifier }}
        aws_additional_tags: ${{ inputs.aws_extra_tags }}



        gh_input_ansible_extra_vars_file: ${{ inputs.st2_ansible_extra_vars_file }}
        #env_aws_secret: ''
        #env_repo: ''
        #env_ghs: ''
        env_bitops: "ST2_AUTH_USERNAME=${{ inputs.st2_auth_username }},ST2_AUTH_PASSWORD=${{ inputs.st2_auth_password }},ST2_PACKS=${{ inputs.st2_packs }}"

        # EC2
        aws_ec2_instance_create: true
        aws_ec2_ami_filter: 'ubuntu/images/hvm-ssd/ubuntu-focal-20.04-amd64-server-*'
        #aws_ec2_ami_id: ${{ inputs.aws_ami_id }}
        aws_ec2_iam_instance_profile: ${{ inputs.aws_ec2_instance_profile }}
        aws_ec2_instance_type: ${{ inputs.aws_ec2_instance_type }}
        #aws_ec2_create_keypair_sm: ${{ inputs.create_keypair_sm_entry }}
        aws_ec2_instance_public_ip: true

        # AWS Route53 Domains abd Certificates
        aws_r53_enable: true
        aws_r53_domain_name: ${{ inputs.aws_domain_name }}
        aws_r53_sub_domain_name: ${{ inputs.aws_sub_domain }}
        aws_r53_root_domain_deploy: ${{ inputs.aws_root_domain }}
        aws_r53_enable_cert: ${{ steps.set-cert.outputs.enable_cert }}
        aws_r53_cert_arn: ${{ inputs.aws_cert_arn }}
        aws_r53_create_root_cert: ${{ inputs.aws_create_root_cert }}
        aws_r53_create_sub_cert: ${{ inputs.aws_create_sub_cert }}

        # AWS ELB
        aws_elb_create: true
        aws_elb_app_port: "443"
        aws_elb_app_protocol: ssl
        #aws_elb_listen_port: ${{ inputs.lb_port }}
        aws_elb_healthcheck: "HTTPS:443/"

        # AWS EFS
        # aws_efs_create: false
        # aws_efs_create_ha: ${{ inputs.aws_create_ha_efs }}
        # aws_efs_create_replica: ${{ inputs.aws_create_efs_replica }}
        # aws_efs_enable_backup_policy: ${{ inputs.aws_enable_efs_backup_policy }}
        # aws_efs_zone_mapping: ${{ inputs.aws_efs_zone_mapping }}
        # aws_efs_transition_to_inactive: ${{ inputs.aws_efs_transition_to_inactive }}
        # aws_efs_replication_destination: ${{ inputs.aws_replication_configuration_destination }}
        # aws_efs_mount_id: ${{ inputs.aws_mount_efs_id }}
        # aws_efs_mount_security_group_id: ${{ inputs.aws_mount_efs_security_group_id }}
        # aws_efs_ec2_mount_point: ${{ inputs.application_mount_target }}
        # aws_efs_mount_target: ${{ inputs.efs_mount_target }}

        # POSTGRES
        # aws_postgres_enable: ${{ inputs.aws_enable_postgres }}
        # aws_postgres_engine:  ${{ inputs.aws_postgres_engine }}
        # aws_postgres_engine_version:  ${{ inputs.aws_postgres_engine_version }}
        # aws_postgres_instance_class: ${{ inputs.aws_postgres_instance_class }}
        # aws_postgres_subnets: ${{ inputs.aws_postgres_subnets }}
        # aws_postgres_database_name: ${{ inputs.aws_postgres_database_name }}
        # aws_postgres_database_port: ${{ inputs.aws_postgres_database_port}}

        # DOCKER
        #docker_install: true
        #docker_repo_app_directory: ${{ inputs.app_directory }}
        #docker_efs_mount_target: ${{ inputs.data_mount_target }}
